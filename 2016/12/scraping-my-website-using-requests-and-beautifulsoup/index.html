<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"  lang="en-us">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1"/>

<title>Scraping my website using requests and BeautifulSoup | Plogging Dev</title>


<link rel="stylesheet" href="https://www.ploggingdev.com//css/style.css"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="theme-color" content="#ffffff">

<meta name="keywords" content="python 3, webscraping, BeautifulSoup, requests, webbrowser">

</head>
<body>

<section class="section">
  <div class="container">
    <nav class="nav">
      <div class="nav-left">
        <a class="nav-item" href="https://www.ploggingdev.com/"><h1 class="title is-4">Plogging Dev</h1></a>
      </div>
      <div class="nav-right">
        <nav class="nav-item">
          <a href="https://www.ploggingdev.com/about">About</a>
          &nbsp;&nbsp;&nbsp;
          <a href="https://www.ploggingdev.com/archive">Archive</a>
        </nav>
      </div>
    </nav>
  </div>
</section>

<section class="section">
  <div class="container">
    <div class="subtitle is-6 is-pulled-right">
      
    </div>
    <h2 class="subtitle is-6">December 8, 2016</h2>
    <h1 class="title">Scraping my website using requests and BeautifulSoup</h1> 
    <div class="content">
      <p>Ok, I didn&rsquo;t use Scrapy because I am yet to go through it&rsquo;s documentation. I will explore Scrapy in an upcoming blog post.</p>

<p>Before getting to write code to scrape my website, I will cover the basics of the following modules:</p>

<ul>
<li><p><code>webbrowser</code></p></li>

<li><p><code>requests</code></p></li>

<li><p><code>BeautifulSoup</code></p></li>
</ul>

<p>The <code>webbrowser</code> module is a builtin module in Python . There is not a lot to explore in this module, except the <code>open(url)</code> method. All it does is open the the default browser to a specified URL.</p>

<p>Example:</p>

<pre><code>import webbrowser

urls = [&quot;https://automatetheboringstuff.com/&quot;, &quot;https://automatetheboringstuff.com/chapter11/&quot;]

for link in urls:
   webbrowser.open(link)
</code></pre>

<p></p>

<p>The above code opens the links in the default browser. It should be noted that running the above code when no browser is open will cause an error message in Firefox. The message is something like &ldquo;Firefox is already running&rdquo;. This happens because the <code>webbrowser</code> module detects that there is no browser open, and tries to open a new window for both links. Why both links? Probably because the second <code>webbrowser.open(url)</code> method is called before the first call causes Firefox to start. How can this be avoided? A hacky solution is to use <code>time.sleep(n seconds)</code> only after the first call to <code>webbrowser.open()</code>. Another way is to just keep a Firefox window open, so all calls to <code>webbrowser.open()</code> will open the link in a new tab. There are probably more elegant ways around this problem, let me know if you aware of any.</p>

<p>The <code>requests</code> library lets us make HTTP requests without worrying about network errors, connection problems, and data compression. It can make <code>get</code>, <code>put</code>, and <code>delete</code> requests among others.</p>

<p>In the following example, <code>requests</code> is used to get the homepage of this website and print some basic information about the response. The html response is saved to <code>mysite.html</code>.</p>

<pre><code>import requests

res = requests.get('https://www.ploggingdev.com')
res.raise_for_status()

#print(res.text)
print(&quot;{} bytes&quot;.format(len(res.text)))
print(&quot;HTTP status code: {}&quot;.format(res.status_code))
print(&quot;response object type: {}&quot;.format(type(res)))

mysite = open(&quot;mysite.html&quot;, &quot;wb&quot;)

print(&quot;Writing the response content to mysite.html&quot;)

for chunk in res.iter_content(10000):
    mysite.write(chunk)

mysite.close()

print(&quot;Done writing&quot;)

#output
11681 bytes
HTTP status code: 200
response object type: &lt;class 'requests.models.Response'&gt;
Writing the response content to mysite.html
Done writing
</code></pre>

<p>Some points to note:</p>

<ul>
<li><p><code>res.raise_for_status()</code> is used to raise an exception if an error occurs while downloading</p></li>

<li><p>When writing the response html to a file, the file is opened in <code>wb</code> mode to maintain the Unicode encoding of the text.</p></li>

<li><p><code>res.iter_content(bytes)</code> returns the specified number of bytes of the response content. This is useful when working with large responses.</p></li>
</ul>

<p>If you don&rsquo;t already know about Unicode and character sets, read this <a href="https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/">post</a>.</p>

<p>Once the html content of a webpage has been retrieved, we need a library to parse the html. This is where <code>BeautifulSoup</code> comes in.</p>

<p>A <code>BeautifulSoup</code> object is created by passing in html content. The html content can be in the form of <code>res.text</code> using the <code>requests</code> module or can be a text file.</p>

<p>Briefly, <code>BeautifulSoup</code> lets us:</p>

<ul>
<li><p>find elements in html using the <code>select()</code> method. The selection can be made using html tags, ids. Additionally attributes can also be specified.</p></li>

<li><p>Data associated with an attribute can be retieved.</p></li>
</ul>

<p>Learn more about how to use <code>BeautifulSoup</code> by following the links at the end of this post.</p>

<p>Coming to webscraping this website, what am I going to scrape? The url, title and keywords associated with every article.</p>

<p>How will I accomplish this?</p>

<ul>
<li><p>Hard code the url of the first blog post</p></li>

<li><p>create lists to hold urls, keywords and titles for every article</p></li>

<li><p>Inside a <code>while True:</code> loop, record the current blog url</p></li>

<li><p>fetch the content hosted at the current blog url using <code>requests</code>.</p></li>

<li><p>Use <code>BeautifulSoup</code> to parse the current page and extract the title and keywords for the current page</p></li>

<li><p>Store the title and keywords for the current post</p></li>

<li><p>try to locate the link that leads to the next post and follow it</p></li>

<li><p>if the link to the next page is not found, it means that we have reached the latest blog and it&rsquo;s time to stop scraping.</p></li>
</ul>

<p>I added keywords to all blog posts recently and this will be an oppurtunity to check if the keywords have made it into all blogs. Why wouldn&rsquo;t the keywords make it into the blogs if I added them? I use Hugo for this site. Sometimes if there is a typo while specifying the keywords (eg- an extra comma) then the <code>&lt;meta name=&quot;keywords&quot;</code> tag won&rsquo;t be generated.</p>

<p>Code:</p>

<pre><code>import requests
import bs4

print(&quot;Fetching all blog posts&quot;)

current_url = 'https://www.ploggingdev.com/2016/11/hello-world/'

urls = list()
titles = list()
keywords = list()

while True:
    urls.append(current_url)

    res = requests.get(current_url)
    res.raise_for_status()

    current_page = bs4.BeautifulSoup(res.text,&quot;html.parser&quot;)
    
    current_title = current_page.select('title')[0].getText()
    titles.append(current_title)

    current_keywords = current_page.select('meta[name=&quot;keywords&quot;]')[0].get('content')
    keywords.append(current_keywords)

    #url for next blog post
    try:
        current_url = current_page.select('ul[class=&quot;pager blog-pager&quot;] &gt; li[class=&quot;next&quot;] &gt; a')[0].get('href')
    except IndexError as ie:
        break

#printing all my blog posts with urls. It's number from 1 to n

zipped = zip(range(1, len(urls)+1), titles, urls, keywords)

for blog_num, blog_title, blog_url, blog_keywords in zipped:
    print(blog_num)
    print(blog_title)
    print(blog_url)
    print(blog_keywords)
    print()
</code></pre>

<p>Output:</p>

<pre><code>Fetching all blog posts
1
Hello World
https://www.ploggingdev.com/2016/11/hello-world/
plogging dev, hello world

2
Beginning Python 3
https://www.ploggingdev.com/2016/11/beginning-python-3/
python 3, Beginning python 3

3
Data types in Python 3
https://www.ploggingdev.com/2016/11/data-types-in-python-3/
python 3, beginning python 3, data types in python 3, datatypes in python 3, boolean in python 3, ints in p
ython 3, floats in python 3

4
Strings in Python 3
https://www.ploggingdev.com/2016/11/strings-in-python-3/
python 3, data types in python 3, datatypes in python 3, strings in python 3
</code></pre>

<p>I won&rsquo;t include the complete output here, but the program successfully scraped all the blog posts. You can find the output <a href="https://gist.github.com/ploggingdev/343a0636e9696eac6799211d4f4385f8">here</a>.</p>

<p>Code for today&rsquo;s plog:</p>

<ul>
<li><p><a href="https://github.com/ploggingdev/python_learn/blob/master/webbrowser_demo.py">Using webbrowser module</a></p></li>

<li><p><a href="https://github.com/ploggingdev/python_learn/blob/master/webscraping.py">Code for requests and BeautifulSoup demo</a></p></li>
</ul>

<p>References:</p>

<ul>
<li><p><a href="https://automatetheboringstuff.com/chapter11/">automatetheboringstuff</a></p></li>

<li><p><a href="http://docs.python-requests.org/en/master/">Requests docs</a></p></li>

<li><p><a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup docs</a></p></li>

<li><p><a href="https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/">Unicode by Joel Spolsky</a></p></li>
</ul>
    </div>
    <section class="section">
      <div class="container">
        <nav class="level is-mobile">
          <div class="level-left">
            <div class="level-item">
              
                  <a class="button" href="https://www.ploggingdev.com/2016/12/decorators-in-python-3/" title="Decorators in Python 3">
                    <span class="icon is-small is-marginless">
                      <svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <polyline points="15 18 9 12 15 6"/>
    
  </svg>
                    </span>
                    Previous
                  </a>
                       
            </div>
          </div>
          <div class="level-right is-marginless">
            <div class="level-item">
              
                  <a class="button" href="https://www.ploggingdev.com/2016/12/analyzing-programming-language-statistics-of-100000-github-repositories/" title="Analyzing programming language statistics of 100,000 Github repositories">Next
                    <span class="icon is-small is-marginless">
                      <svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <polyline points="14 6 20 12 14 18"/>
    
  </svg>
                    </span></a>
              
            </div>
          </div>
        </nav>
      </div>
    </section>
    </br>
</br>
<div id="hosted_comments">
</div>
<script src="https://www.hostedcomments.com/static/js/iframeResizer.min.js">
</script>
<script>
 var hc_config = function () {
            page_url = window.location.href;
            spa = false;
            website_identifier = 'admin_PloggingDev';
            };

        (function() {  
            var d = document, s = d.createElement('script');
            s.src = 'https://www.hostedcomments.com/static/js/embed.js';
            (d.head || d.body).appendChild(s);
        })();
</script>
<noscript>
 Please enable javascript to view the comments powered by
 <a href="https://www.hostedcomments.com">
  Hosted Comments
 </a>
 .
</noscript>
  </div>
</section>
<section class="section">
  <div class="container has-text-centered">
    <p><a class="level-item" href='mailto:ploggingdev@gmail.com' target='_blank' rel='noopener'>
          <span class="icon">
            <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"/>
    <polyline points="22,6 12,13 2,6"/>
    
  </svg></i>
          </span>
        </a>
        &nbsp;<a class="level-item" href='https://github.com/ploggingdev' target='_blank' rel='noopener'>
          <span class="icon">
            <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/>
    
  </svg></i>
          </span>
        </a>
        &nbsp;<a class="level-item" href='https://twitter.com/ploggingdev' target='_blank' rel='noopener'>
          <span class="icon">
            <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"/>
    
  </svg></i>
          </span>
        </a>
        &nbsp;</p>
    <br />
    <p>&copy; Plogging Dev - Powered by <a href='https://gohugo.io/'>Hugo</a> Theme by <a href='https://github.com/ribice/kiss'>Kiss</a></p>
    
  </div>
</section>
<link rel="stylesheet"
      href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-86436693-1 ', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


</body>
</html>
